// Thanks to Neetcode for the inspo 
// used big Os beacause of haha 

O(1) {
    Does not matter how big the in putsize grows the run time will remain the same 
    Constant time operations:

    #Array
        nums = [1, 2, 3]
        nums.append(4);      // push to end 
        nums.pop();          // remove from end
        nums[0];             // look ups 
        nums[1];
        nums[2];

    #HashMap / Set 
        hashMap = {};
        hashMap["key"] = 10;             // insert
        print("key" in hashMap);         // lookup
        print(hashMap["key"]);           // lookup
        hashMap.pop("key");              // remove
}

O(n) {
    Linear functions basically the more data you have the longer the runtime will be 
    for more about this refer back to linear algebra come on you know this 
    Examples:

        #Array
            nums = [1, 2, 3];            // example list
            sum(nums)                    // sum of array
            for n in nums:              // loops 
                print(n);

            nums.insert (1, 100);                // middle insertions 
            nums.remove(100);                    // middle erases 
            print(100 in nums);                  // search

            import heapq           
            heapq.heapify(nums)         // heap building

            // sometimes nested loops can be O(n)
}

O(n^2) {
    For two dimensional arrays. it's n^2 cause it traverses through a 2 dimensional matrix.
    Examples:

        #TraversingMatrixArray

            nums = [[1, 2, 3], [1, 2, 3], [1, 2, 3]]
            for i in range(len(nums)):
                fo j in range(len(nums[i])):
                    print(nums[i][j]);
        
        #GetEveryPair

            nums = [1, 2, 3]
            for i in range(i + 1, len(nums)):
                print(nums[i], nums[j]);

        // Insertion sort 
}

O(logn) {
    the log is to calculate relative change of value.
    It is the inverse function to exponentiation.
    Phone book example from harvard cs50!
    It eliminates half of the elements of the list on each iteration
    making for a sweet runtime.
    Follows the divide and conquer principle.

        #MathAhead?

            2^x = n
            x = logn
}


Applications/UseCases by John Feminella using phone book analogy on Stack overflow {

    #PhoneBookUnexpected

        O(1) (in the worst case): Given the page that a business's 
        name is on and the business name, find the phone number.

        O(1) (in the average case): Given the page that a person's 
        name is on and their name, find the phone number.

        O(log n): Given a person's name, find the phone number 
        by picking a random point about halfway through the part 
        of the book you haven't searched yet, then checking to 
        see whether the person's name is at that point. 
        Then repeat the process about halfway through the part 
        of the book where the person's name lies. 
        (This is a binary search for a person's name.)

        O(n): Find all people whose phone numbers contain the digit "5".

        O(n): Given a phone number, find the person or business with that number.

        O(n log n): There was a mix-up at the printer's office, and our phone book
        had all its pages inserted in a random order. Fix the ordering so that
        it's correct by looking at the first name on each page and then putting 
        that page in the appropriate spot in a new, empty phone book.
}


